---
format: 
    revealjs:
        theme: night
        transition: fade
        css: css/styles.css
        footer: '<a href="https://github.com/mrguyperson/leibniz_interview" target="_blank">View on GitHub</a>'
        logo: images/igb.jpg
title: "Data Analyst in Bioinformatics and Ecology"
author: Theodore Hermann
date: 21 August, 2025
title-slide-attributes:
  data-notes: |
    Hi everyone â€” and thanks so much for the chance to talk with you today. Iâ€™m Ted Hermann, and Iâ€™d like to spend the next few minutes walking you through my background, how I see my experience aligning with this position, and why Iâ€™m genuinely excited about the opportunity to support your work at IGB.

---

## Background
- ğŸï¸ Freshwater biology + data science  
- ğŸ’» Biologist with a programmerâ€™s mindset  
- ğŸŒ Reproducibility advocate  
- ğŸ¤ Service-focused  

::: {.notes}

My background blends biology, programming, and applied problem-solving. Across research, consulting, and freelance work, the throughline has been building tools, workflows, and analyses that other people can use â€” scientists, engineers, and decision-makers.

That service focus has been consistent, so Iâ€™ll share three quick examples.

:::


## Experience {.smaller}

::: {.notes}

At UC Santa Cruz, I helped build FHAST, a simulation toolkit for river managers. My role was to make sure it wasnâ€™t just research code, but usable software â€” delivered on time, tested with stakeholders, and documented so it could keep being used after our team moved on.

:::

ğŸŸ Postdoc: FHAST (UC Santa Cruz)

- Open-source agent-based modeling toolkit for fish habitat analysis â†’ Allowed research groups and agencies to run habitat simulations reproducibly and without advanced coding expertise.

. . . 

::: {.notes}

At the Electric Power Research Institute, I worked with engineers to build a Python ML pipeline for detecting equipment defects. My role was translating domain expertise into a clean, reproducible, maintainable workflow. We delivered a documented repo and a retraining script so their team could adapt the model independently.

:::


ğŸ”Œ Consultation: EPRI Heat Exchanger ML Pipeline

- Machine learning pipeline for heat exchanger fault detection â†’ Helped engineers rapidly identify component failures, reducing downtime and maintenance costs.

. . .

::: {.notes}

I also spent years as a technical editor, helping scientists and companies get papers, grants, and books over the finish line â€” often with non-native English authors. Pure service work: success measured by clientsâ€™ success.

So whether it was software for river managers, a pipeline for engineers, or editing manuscripts for scientists, the common thread was service â€” making sure others had what they needed to succeed.

But across these roles, I also saw how fragile research processes could be. Thatâ€™s what first pushed me to dig deeper into reproducible science.  

I kept running into problems that frustrated me, and I saw it happening to colleagues too:

:::


ğŸ“ Freelance: Technical Editing & Writing Support

- Editor for scholars & companies â†’ helped clients publish, secure grants, and communicate clearly




## Science Gets Messy {.smaller}

<div style="text-align: center;"> <img src="images/this_is_fine.jpg" height="400"> </div>

::: {.notes}

Collaborative work can lead to chaos with file versions.

Code might run on one computer but fail on another.

Giant scripts that are failure-prone and impossible to debug months later.

And even when research makes it into a paper, the methods rarely spell out how raw data became results. Reproducibility often stops at the manuscript.

Instead of just accepting those frustrations as the cost of doing science, I started looking for ways to fix them. Over time, that search grew into the structured, reproducible workflow I use today.
:::


## Solutions that Work

:::: {.columns}

::: {.fragment .fade-in-then-out .overlay}

```{.r}
library(targets)
library(tarchetypes)
library(here)

tar_option_set(
  packages = c("tidyverse")
)

tar_source()

list(
    tar_target(
        name = path,
        command = here("path/to/data.csv"),
        format = "file"
    ),
    tar_target(
        name = raw_data,
        command = read_data(path)
    ),
    tar_target(
        name = analyzed_data,
        command = analyze_data(raw_data)
    ),
    tar_render(
        name = manuscript,
        path = here("path/to/manuscript.qmd")
    )
)
```
:::

::: {.column width="80%"}


- Pipelines â†’ teammates can rerun analyses without guesswork

- Controlled environments â†’ collaborators get the same results every time

- Version control â†’ workflows open for team and community to reuse

- Documentation â†’ future researchers can build on the work without me present

:::

::: {.column width="20%"}

![](images/targets.png){.absolute height="100" right="40" top="90"}

![](images/docker.png){.absolute height="80" right="70" top="230"}
![](images/renv.png){.absolute height="80" right="-10" top="230"}

![](images/git.png){.absolute height="70" right="50" top="360"}

![](images/quarto.png){.absolute height="50" right="-10" top="490"}

:::

::: {.notes}


The first thing I tackled was pipelines. Instead of fragile, thousand-line scripts, I use structured project layouts and a pipeline manager so analyses can be rerun without guesswork â€” not just by me, but by collaborators down the line. 

My go-to is the **targets** package in R, which can reproduce an entire project, including manuscripts, with a single command.

Pipelines donâ€™t fix everything, so I lock environments. **Docker** standardizes the system across machines, and **renv** freezes R package versions. That way others â€” even years later â€” can run the code exactly as I did.

For collaboration, I put code, data, and documentation on **GitHub** so nothing lives on one laptop or buried as 10 versions in email threads. It keeps the workflow transparent for the team and open to the wider community for audit and reuse.

Finally, **documentation** â€” clear READMEs, inline notes, and **Quarto** reports â€” means future researchers can understand and extend the work without me in the room.

*These practices are deliberately general.* The same pattern â€” modular steps, QC checkpoints, and versioned environments â€” extends across ecology, genomics (FASTQ/VCF), and even metadata/DMP basics; while I havenâ€™t authored formal DMPs yet, but the workflow supports them out of the box.

For me, the point of all this isnâ€™t reproducibility for its own sake â€” itâ€™s giving people tools that actually save time and reduce stress.

:::

::::

<span class="fragment step-hold" aria-hidden="true"></span>


## Reality of Research {.smaller}

::: {.notes}

But even with great tools, adoption isnâ€™t instant. Scientists are busy, projects are bespoke, and thereâ€™s rarely time to refactor workflows with deadlines looming.

Thatâ€™s why I see reproducibility itself as a service. A dedicated person can package pipelines, environments, and templates to reduce the burden on scientists and ensure that best practices are easy to implement.

The payoff is twofold: researchers keep their focus on the science, and the institute gains robust, transparent, reusable workflows that speed up work instead of slowing it down.

So the question is: how do we turn these practices into shared infrastructure the whole institute can rely on? Thatâ€™s exactly where Iâ€™d like to contribute.

:::


<div style="text-align: center;"> <img src="images/busy.jpg" height="400"> </div>

## How I Can Contribute
- ğŸï¸ Freshwater expertise
- ğŸ’» Technical range (R/Python, pipelines)
- ğŸŒ Open, shareable workflows
- ğŸ¤ Reproducibility as a service


::: {.notes}

What excites me about IGB is building this as shared infrastructure: pipelines and environments that make projects easier to trust, reuse, and extend across teams.

Thatâ€™s the role Iâ€™m looking for â€” not just producing results myself, but making the *whole* instituteâ€™s work more reproducible, faster to iterate on, and easier to share because of the tools we build together.

Thatâ€™s the contribution Iâ€™d be excited to make with you.

:::


## Questions?

::: {.notes}
Just a final note: this talk was made using Quarto and all files are available on GitHub!
:::


<div style="text-align: center;">
  <img src="images/drake_meme.jpg" height="400">
</div>