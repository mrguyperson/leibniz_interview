---
format: 
    revealjs:
        theme: night
        transition: fade
        css: css/styles.css
        footer: '<a href="https://github.com/mrguyperson/leibniz_interview" target="_blank">View on GitHub</a>'
title: "Data Analyst in Bioinformatics and Ecology"
author: Theodore Hermann
date: 21 August, 2025
title-slide-attributes:
  data-notes: |
    Hi everyone ‚Äî and thanks so much for the chance to talk with you today. I‚Äôm Ted Hermann, and I‚Äôd like to spend the next few minutes walking you through my background, how I see my experience aligning with this position, and why I‚Äôm genuinely excited about the opportunity to support your work at IGB.

---

## Background
:::: {.columns}
::: {.column width="75%"}

- Ph.D. Biology, M.P.A. ‚Äì bridging science, policy, and data
- 5+ years of experience in data science, modeling, and analysis
- Open science advocate: reproducible, transparent workflows
- Consistently deliver tools, analyses, and support that help others succeed
:::

::: {.column width="25%"}
![](images/catfish.png){.absolute height="150" top="90" right="80"}
![](images/code.png){.absolute height="80" top="240" right="120"}
![](images/opensci.png){.absolute height="100" top="350" right="120"}
![](images/service.png){.absolute height="100" top="450" right="120"}


:::

::::

::: {.notes}

My background blends biology, programming, and applied problem-solving. Across research, consulting, and freelance work, the throughline has been building tools, workflows, and analyses that other people can use ‚Äî scientists, engineers, and decision-makers.

That service focus has been consistent, so I‚Äôll share three quick examples.

:::


## Experience {.smaller}

::: {.notes}

At UC Santa Cruz, I helped build FHAST, a simulation toolkit for river managers. My role was to make sure it wasn‚Äôt just research code, but usable software ‚Äî delivered on time, tested with stakeholders, and documented so it could keep being used after our team moved on.

:::

üêü Postdoc: FHAST (UC Santa Cruz)

- Open-source agent-based modeling toolkit for fish habitat analysis ‚Üí Allowed research groups and agencies to run habitat simulations reproducibly and without advanced coding expertise.

. . . 

::: {.notes}

At the Electric Power Research Institute, I worked with engineers to build a Python ML pipeline for detecting equipment defects. My role was translating domain expertise into a clean, reproducible, maintainable workflow. We delivered a documented repo and a retraining script so their team could adapt the model independently.

:::


üîå Consultation: EPRI Heat Exchanger ML Pipeline

- Machine learning pipeline for heat exchanger fault detection ‚Üí Helped engineers rapidly identify component failures, reducing downtime and maintenance costs.

. . .

::: {.notes}

I also spent years as a technical editor, helping scientists and companies get papers, grants, and books over the finish line ‚Äî often with non-native English authors. Pure service work: success measured by clients‚Äô success.

So whether it was software for river managers, a pipeline for engineers, or editing manuscripts for scientists, the common thread was service ‚Äî making sure others had what they needed to succeed.

But across these roles, I also saw how fragile research processes could be. That‚Äôs what first pushed me to dig deeper into reproducible science.  

:::


üìù Freelance: Technical Editing & Writing Support

- Editor for scholars & companies ‚Üí helped clients publish, secure grants, and communicate clearly


## Reproducible Science {.smaller}
::: {.notes}
Science is often bespoke ‚Äî every dataset is different, and unlike professional software, research rarely starts with standardized workflows. Add in deadlines and limited time, and it‚Äôs natural for quick fixes to pile up.

That‚Äôs not a criticism ‚Äî I‚Äôve been there myself. Scientists are busy, and the priority is keeping projects moving. That‚Äôs exactly why reproducible workflows as a service matter: they take some of that burden off researchers, while still giving them tools that are robust, transparent, and ready to use.

Science takes time, it gets messy, and has a lot of issues I'm sure we've all encountered at some point:

:::

. . .

Science gets messy

<div style="text-align: center;"> <img src="images/this_is_fine.jpg" height="400"> </div>

::: {.notes}

Collaborative work can lead to chaos with file versions.

Code might run on one computer but fail on another.

Giant scripts that are failure-prone and impossible to debug months later.

And even when research makes it into a paper, the methods rarely spell out how raw data became results. Reproducibility often stops at the manuscript.

Instead of just accepting those frustrations as the cost of doing science, I started looking for ways to fix them. Over time, that search grew into the structured, reproducible workflow I use today.
:::


## Reproducible Science {.smaller}

Solutions:

:::: {.columns}

::: {.fragment .fade-in-then-out .overlay}

```{.r}
library(targets)
library(tarchetypes)
library(here)

tar_option_set(
  packages = c("tidyverse")
)

tar_source()

list(
    tar_target(
        name = path,
        command = here("path/to/data.csv"),
        format = "file"
    ),
    tar_target(
        name = raw_data,
        command = read_data(path)
    ),
    tar_target(
        name = analyzed_data,
        command = analyze_data(raw_data)
    ),
    tar_render(
        name = manuscript,
        path = here("path/to/manuscript.qmd")
    )
)
```
:::

::: {.column width="75%"}


- Pipelines ‚Üí teammates can rerun analyses without guesswork

- Controlled environments ‚Üí collaborators get the same results every time

- Version control ‚Üí workflows open for team and community to reuse

- Documentation ‚Üí future researchers can build on the work without me present

:::

::: {.column width="25%"}

![](images/targets.png){.absolute height="70" right="140" top="140"}

![](images/docker.png){.absolute height="70" right="160" top="220"}
![](images/renv.png){.absolute height="70" right="60" top="220"}

![](images/git.png){.absolute height="60" right="140" top="310"}

![](images/quarto.png){.absolute height="40" right="90" top="410"}

:::

::: {.notes}


The first thing I tackled was pipelines. Instead of fragile, thousand-line scripts, I use structured project layouts and a pipeline manager so analyses can be rerun without guesswork ‚Äî not just by me, but by collaborators down the line. 

My go-to is the **targets** package in R, which can reproduce an entire project, including manuscripts, with a single command.

Pipelines don‚Äôt fix everything, so I lock environments. **Docker** standardizes the system across machines, and **renv** freezes R package versions. That way others ‚Äî even years later ‚Äî can run the code exactly as I did.

For collaboration, I put code, data, and documentation on **GitHub** so nothing lives on one laptop or buried as 10 versions in email threads. It keeps the workflow transparent for the team and open to the wider community for audit and reuse.

Finally, **documentation** ‚Äî clear READMEs, inline notes, and **Quarto** reports ‚Äî means future researchers can understand and extend the work without me in the room.

For me, the point of all this isn‚Äôt reproducibility for its own sake ‚Äî it‚Äôs giving people tools that actually save time and reduce stress. And stepping back, that‚Äôs the pattern in my work: turning messy challenges into reliable, reusable solutions others can trust and build on.


:::

::::

<span class="fragment step-hold" aria-hidden="true"></span>


## How I Can Contribute

- Freshwater expertise: domain knowledge to ramp up quickly

- Proven service mindset: success measured by enabling others

- Technical range: coding, pipelines, reproducibility

- Commitment to open science: transparent, shareable workflows

::: {.notes}

What excites me about IGB is its focus on service ‚Äî building data management and research support as shared infrastructure. That‚Äôs where my freshwater background and technical skills can contribute most: helping the whole team‚Äôs work be stronger, more reproducible, and more impactful.

That‚Äôs the role I‚Äôm looking for ‚Äî not just producing results myself, but making sure the infrastructure we build together helps the institute move faster with confidence.

That‚Äôs the contribution I‚Äôd be excited to make with you.

:::


## Questions?

::: {.notes}
Just a final note: this talk was made using Quarto and all files are available on GitHub!
:::


<div style="text-align: center;">
  <img src="images/drake_meme.jpg" height="500">
</div>
